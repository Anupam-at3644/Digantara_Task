{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc27c095",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b793910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sgp4.api import Satrec, jday\n",
    "import pyproj\n",
    "from timeit import default_timer as timer\n",
    "import dask.delayed\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar, Profiler, ResourceProfiler, visualize\n",
    "#dask.config.set(scheduler='threads')\n",
    "\"\"\"\n",
    "# One can create a particular Client depending on machine capability or multiple machines. Then, use the client to compute dask.delayed objects\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers = 4, threads_per_worker = 1)\n",
    "c = Client(cluster)\n",
    "c.cluster\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26481c",
   "metadata": {},
   "source": [
    "# Satellite count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033f614",
   "metadata": {},
   "source": [
    "# Functions to create Time Series (JD, FR) from datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2abde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series(start_date, end_date):\n",
    "    start_date = np.datetime64(start_date)\n",
    "    end_date = np.datetime64(end_date)\n",
    "\n",
    "    # for 1 sec intervals\n",
    "    #time_series = np.arange(start_date, end_date, np.timedelta64(1, 's'))\n",
    "    # for 0.1 sec intervals\n",
    "    time_series = np.arange(start_date, end_date, np.timedelta64(100, 'ms'))\n",
    "    \n",
    "    return time_series\n",
    "\n",
    "def JD_FR(time_series):\n",
    "    # creating a wrapper function for map\n",
    "    def jday_wrap(instance):\n",
    "        dt = instance.astype(object)\n",
    "        return jday(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "    # return JD, FR\n",
    "    return map(np.array, zip(*map(jday_wrap, time_series)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5d8fb",
   "metadata": {},
   "source": [
    "# Delayed functions (parallelized) for coordinate transformation using Pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for x, y, z coordinates from satellite object\n",
    "@dask.delayed(nout = 1, pure = True)\n",
    "def dist(satellite, JD, FR):\n",
    "    # satellite.sgp4_array returns e, r, v. We are interested in r.\n",
    "    return satellite.sgp4_array(JD, FR)[1]\n",
    "\n",
    "# function to calculate Longitude, Latitude, Altitude\n",
    "# describing the transformer outside the function avoids creating the same object (encapsulation of transformer parameters) repeatedly\n",
    "transformer = pyproj.Transformer.from_crs({\"proj\":'geocent', \"ellps\":'WGS84', \"datum\":'WGS84'}, {\"proj\":'latlong', \"ellps\":'WGS84', \"datum\":'WGS84'})\n",
    "# use delayed decorator for parallization\n",
    "@dask.delayed(nout = 3, pure = True)\n",
    "def ecef2lla(pos_x, pos_y, pos_z):\n",
    "    # return long, lati, alti \n",
    "    return [transformer.transform(pos_x, pos_y, pos_z, radians = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe28c816",
   "metadata": {},
   "source": [
    "# Function to read target file and create satellite objects using Pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_satellite_array(file):\n",
    "    count = COUNT\n",
    "    satellite_array = []\n",
    "    # use context manager to optimally open/close files\n",
    "    with open(file, 'r') as sat:\n",
    "        while count > 0:\n",
    "            s = sat.readline()\n",
    "            t = sat.readline()\n",
    "        \n",
    "            satellite_array.append(Satrec.twoline2rv(s, t))\n",
    "            count -= 1\n",
    "    return satellite_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f3f43",
   "metadata": {},
   "source": [
    "# Setup for user-defined region to filter LLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53476721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#region latitude and longitude coordinates\n",
    "#the implemented search is naive and equivalent to a rectangular area of search, i.e, larger than or equal to exact\n",
    "#the area chosen is small to receive fewer final results\n",
    "la_1, lo_1 = 16.66673, 18.58196\n",
    "la_2, lo_2 = 19.74973, 17.64459\n",
    "la_3, lo_3 = 17.09096, 19.71009\n",
    "la_4, lo_4 = 18.32309, 16.79778\n",
    "\n",
    "la_min = min(la_1, la_2, la_3, la_4)\n",
    "la_max = max(la_1, la_2, la_3, la_4)\n",
    "lo_min = min(lo_1, lo_2, lo_3, lo_4)\n",
    "lo_max = max(lo_1, lo_2, lo_3, lo_4)\n",
    "\n",
    "#function to filter long and lat that fall in the region\n",
    "def filter_lon_lat(lo, la):\n",
    "    return la < la_max and la > la_min and lo < lo_max and lo > lo_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909bd34",
   "metadata": {},
   "source": [
    "# Optional function to write filtered results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ea77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(satellite_num, L, Lo, La, time_series):\n",
    "    with open(\"Final_result\", 'a') as f:\n",
    "        for j in range(L):\n",
    "            if filter_lon_lat(Lo[j], La[j]):\n",
    "                f.write(\"{} | {} | {} | {}\\n\".format(satellite_num+1, time_series[j], Lo[j], La[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166db1a",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    start_date = '2023-01-01T00:00:00'\n",
    "    end_date = '2023-01-06T00:00:00'\n",
    "    # file in same directory as jupyter notebook\n",
    "    #file = '30sats.txt'\n",
    "    file = '27000sats.txt'\n",
    "    \n",
    "    start = timer()\n",
    "    copy = start\n",
    "    time_series = create_time_series(start_date, end_date)\n",
    "    print(\"Creating time_series:\", timer()-start)\n",
    "\n",
    "    start = timer()\n",
    "    JD, FR = JD_FR(time_series)\n",
    "    #print(L)\n",
    "    print(\"Creating JD, FR:\", timer()-start)\n",
    "    L = len(time_series)\n",
    "    \n",
    "    start = timer()\n",
    "    satellite_array = create_satellite_array(file)\n",
    "    print(\"Creating satellite objects:\", timer()-start)\n",
    "\n",
    "    results = []\n",
    "    for i in range(COUNT):\n",
    "        r = 1000*dist(satellite_array[i], JD, FR).ravel() \n",
    "        result = ecef2lla(r[0::3], r[1::3], r[2::3])\n",
    "        results.append(result)\n",
    "    #print(results)\n",
    "    \n",
    "    # calculate delayed objects in parallel\n",
    "    start = timer()\n",
    "\n",
    "    # compute inside the context of dask workers, CPU, and RAM profilers\n",
    "    with ProgressBar(), Profiler() as prof, ResourceProfiler(dt = 0.25) as rprof:\n",
    "        results = dask.compute(*results)\n",
    "    print(\"Creating LLA:\", timer()-start)\n",
    "    #print(list(results)[0])\n",
    "\n",
    "    #\"\"\"\n",
    "    # filtering and printing results to file\n",
    "    with open(\"Final_result\", 'w') as f:\n",
    "        f.write(\"Satellite | Time | Longitude | Latitude\\n\")\n",
    "    for i in range(COUNT):\n",
    "        (Lo, La, Al) = list(results)[i][0]\n",
    "        #print(Lo, La)\n",
    "        write_to_file(i, L, Lo, La, time_series)\n",
    "    #\"\"\"\n",
    "    print(\"Total:\", timer() - copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1d09a-b723-4faa-bc98-168c416bc2b7",
   "metadata": {},
   "source": [
    "# Graph of each parallel task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d8016-86b6-4fb9-ba3f-46eafa6499c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34a9e2-84f9-4128-938d-0bc95080ef31",
   "metadata": {},
   "source": [
    "# Resource Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ff1d4-20b7-439c-bb85-f251814b8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "prof.visualize()\n",
    "rprof.visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
